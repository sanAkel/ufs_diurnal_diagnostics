{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14NlrtPVsI9ITnUmSAUGaVr7298uNxLBw",
      "authorship_tag": "ABX9TyOgSEa0gmp6mnoUuovITIfW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanAkel/ufs_diurnal_diagnostics/blob/main/ARAFS/prep_data/download_buoy_iQuam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gather case(s) to investigate\n",
        "- [Start with slides from Vijay](https://docs.google.com/presentation/d/1FXhrcXLyC2L1fdVLXxjJq-1IbEAfROW230I02AnYx6M/edit?usp=sharing)\n",
        "- [Look closely at the 12/2022- 01/2023 event.](https://www.ncei.noaa.gov/monitoring-content/sotc/national/2023/jan/ar-total-precip-1-17-23.jpg)"
      ],
      "metadata": {
        "id": "8OneFPKet0m_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inputs\n",
        "\n",
        "\n",
        "- URLs of data to download:\n",
        "  - [in- situ SST from NESDIS iQuam](https://www.star.nesdis.noaa.gov/socd/sst/iquam/index.html)\n",
        "\n",
        "- Start and end dates of `case 1`.  "
      ],
      "metadata": {
        "id": "buyf1VwRKgE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urls = ['https://star.nesdis.noaa.gov/pub/socd/sst/iquam/v2.10/202212-STAR-L2i_GHRSST-SST-iQuam-V2.10-v01.0-fv02.0.nc', 'https://star.nesdis.noaa.gov/pub/socd/sst/iquam/v2.10/202301-STAR-L2i_GHRSST-SST-iQuam-V2.10-v01.0-fv02.0.nc']\n",
        "\n",
        "print(urls)\n",
        "\n",
        "# start and end dates of `case 1`:\n",
        "start_date = date(2022, 12, 20)\n",
        "end_date = date(2023, 1, 20)"
      ],
      "metadata": {
        "id": "MMh5thCtB6HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b3007c5"
      },
      "source": [
        "# Mount (google) drive to be able save data that will be processed\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob as glob\n",
        "\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import date, timedelta"
      ],
      "metadata": {
        "id": "MHy68sV1OOFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_iquam_data(iquam_file_path, obs_ids, obsType):\n",
        "  \"\"\"\n",
        "  Loads iQuam data from a NetCDF file and subsets it based on:\n",
        "  - Observation type.\n",
        "\n",
        "  Args:\n",
        "    iquam_file_path: Path to the iQuam NetCDF file.\n",
        "    obs_ids: Dictionary mapping observation type names to their IDs.\n",
        "    obsType: String representing the desired observation type (e.g., 'buoy').\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing the subsetted data arrays:\n",
        "    (oType_subset, year, month, day, hour, minute, pType, lat, lon, sst, qcFlag)\n",
        "  \"\"\"\n",
        "  ds = xr.open_dataset(iquam_file_path, decode_timedelta=False)\n",
        "\n",
        "  oType = ds.platform_type.values[:]\n",
        "  oType_subset = oType[oType == obs_ids[obsType]]\n",
        "\n",
        "  year = ds.year.values[:][oType == obs_ids[obsType]]\n",
        "  month = ds.month.values[:][oType == obs_ids[obsType]]\n",
        "  day = ds.day.values[:][oType == obs_ids[obsType]]\n",
        "  hour = ds.hour.values[:][oType == obs_ids[obsType]]\n",
        "  minute = ds.minute.values[:][oType == obs_ids[obsType]]\n",
        "\n",
        "  pId = ds.platform_id.values[:][oType == obs_ids[obsType]]\n",
        "\n",
        "  lat = ds.lat.values[:][oType == obs_ids[obsType]]\n",
        "  lon = ds.lon.values[:][oType == obs_ids[obsType]]\n",
        "  sst = ds.sst.values[:][oType == obs_ids[obsType]]\n",
        "  qcFlag = ds.quality_level.values[:][oType == obs_ids[obsType]]\n",
        "\n",
        "  #depth = None\n",
        "  #if obsType == 'Argo':\n",
        "  #depth = ds.depth.values[:][oType == obs_ids[obsType]]\n",
        "\n",
        "  return (oType_subset, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag)"
      ],
      "metadata": {
        "id": "OBr6yvYEPfuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_subset_iquam_data(obsType, oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag, best_quality_value):\n",
        "\n",
        "  mask = qcFlag == best_quality_value\n",
        "\n",
        "  # Apply the mask to all data arrays\n",
        "  oType_filtered = oType[mask]\n",
        "  year_filtered = year[mask]\n",
        "  month_filtered = month[mask]\n",
        "  day_filtered = day[mask]\n",
        "  hour_filtered = hour[mask]\n",
        "  minute_filtered = minute[mask]\n",
        "  pId_filtered = pId[mask]\n",
        "  lat_filtered = lat[mask]\n",
        "  lon_filtered = lon[mask]\n",
        "  sst_filtered = sst[mask]\n",
        "  qcFlag_filtered = qcFlag[mask]\n",
        "\n",
        "  #if obsType == 'Argo':\n",
        "  #depth_filtered = depth[mask]\n",
        "\n",
        "  return (oType_filtered, year_filtered, month_filtered, day_filtered,\n",
        "          hour_filtered, minute_filtered, pId_filtered, lat_filtered,\n",
        "          lon_filtered, sst_filtered, qcFlag_filtered)"
      ],
      "metadata": {
        "id": "j048PPA_PsGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_iquam_by_input_date(oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag, in_year, in_mon, in_day):\n",
        "    \"\"\"\n",
        "    Filters iQuam data arrays based on the input year, month, and day.\n",
        "\n",
        "    Args:\n",
        "        oType, year, month, day, hour, minute, pType, lat, lon, sst, qcFlag: Data arrays.\n",
        "        in_year, in_mon, in_day: Integer values for the year, month, and day of interest.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing the filtered data arrays.\n",
        "    \"\"\"\n",
        "    mask = (year == in_year) & (month == in_mon) & (day == in_day)\n",
        "\n",
        "    oType_filtered = oType[mask]\n",
        "    year_filtered = year[mask]\n",
        "    month_filtered = month[mask]\n",
        "    day_filtered = day[mask]\n",
        "    hour_filtered = hour[mask]\n",
        "    minute_filtered = minute[mask]\n",
        "    pId_filtered = pId[mask]\n",
        "    lat_filtered = lat[mask]\n",
        "    lon_filtered = lon[mask]\n",
        "    sst_filtered = sst[mask]\n",
        "    qcFlag_filtered = qcFlag[mask]\n",
        "\n",
        "    return (oType_filtered, year_filtered, month_filtered, day_filtered,\n",
        "            hour_filtered, minute_filtered, pId_filtered, lat_filtered,\n",
        "            lon_filtered, sst_filtered, qcFlag_filtered)"
      ],
      "metadata": {
        "id": "GLRBAsK-QjGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "a75b63ef"
      },
      "source": [
        "drive_path = '/content/drive/MyDrive/UFS-no-RTOFS/AR/work/data/'\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "for url in urls:\n",
        "  !wget -P \"{drive_path}\" \"{url}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to make sure files have been successfully downloaded\n",
        "\n",
        "iquam_fNames = glob.glob(drive_path + '/*.nc')\n",
        "\n",
        "print(\"The following files are now available:\\n\")\n",
        "for fName in iquam_fNames:\n",
        "  print(fName)"
      ],
      "metadata": {
        "id": "jwcf6B1oM6fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze data from drifting buoys (in above downloaded files):\n",
        "- Drifting buoys follow currents.\n",
        "- They also measure Sea Surface Temperature (SST; at about 20 cm depth)\n",
        "\n",
        "## Note:\n",
        "- Downloaded files have data from a bunch of (other) observing platforms besides drifting buoys."
      ],
      "metadata": {
        "id": "FnvZaCbQO6Ii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "obs_ids = {'ship': 1,\n",
        "          'buoy': 2,\n",
        "          'tMoor': 3,\n",
        "          'cMoor': 4,\n",
        "          'Argo': 5}\n",
        "\n",
        "obsType = 'buoy' # 'buoy' 'cMoor'\n",
        "use_best_quality = True # Use certain quality of obs?\n",
        "best_quality_value = 5 # Threshold for quality flag\n",
        "\n",
        "if obsType == 'Argo':\n",
        "  print(f\"{obsType} is not allowed for now.\\n If aren't looking carefully, bear consequences!\\n\")"
      ],
      "metadata": {
        "id": "Y23hFLVUNL_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset observations of selected type, quality and date\n",
        "\n",
        "current_date = start_date\n",
        "while current_date <= end_date:\n",
        "  iYear, iMon, iDay = [current_date.year, current_date.month, current_date.day]\n",
        "\n",
        "  iquam_fName = glob.glob(drive_path+ f'{iYear}{iMon:02d}*.nc')[0]\n",
        "  print(f'Reading {obsType} from {iquam_fName}')\n",
        "\n",
        "  oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag =\\\n",
        "  load_iquam_data(iquam_fName, obs_ids, obsType)\n",
        "  #print(f\"Number of obs in ENTIRE month: {len(oType), len(sst)}\")\n",
        "\n",
        "  if use_best_quality:\n",
        "    oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag =\\\n",
        "    load_and_subset_iquam_data(obsType, oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag, best_quality_value)\n",
        "    #print(f\"Best quality: {len(oType), len(sst)}\")\n",
        "\n",
        "  oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag = filter_iquam_by_input_date(oType, year, month, day, hour, minute, pId, lat, lon, sst, qcFlag, iYear, iMon, iDay)\n",
        "\n",
        "  if len(sst) > 0:\n",
        "    print(f\"{iYear}/{iMon}/{iDay} \\t Gathered {len(sst)} buoy SSTs.\")\n",
        "\n",
        "    # Create an xarray Dataset\n",
        "    ds_out = xr.Dataset({\n",
        "        'oType': ('obs', oType),\n",
        "        'year': ('obs', year),\n",
        "        'month': ('obs', month),\n",
        "        'day': ('obs', day),\n",
        "        'hour': ('obs', hour),\n",
        "        'minute': ('obs', minute),\n",
        "        'pId': ('obs', pId),\n",
        "        'lat': ('obs', lat),\n",
        "        'lon': ('obs', lon),\n",
        "        'sst': ('obs', sst),\n",
        "        'qcFlag': ('obs', qcFlag)\n",
        "    },\n",
        "    coords={\n",
        "        'obs': np.arange(len(oType))\n",
        "    })\n",
        "    output_filename = f'iquam_{obsType}_{iYear}{iMon:02d}{iDay:02d}.nc'\n",
        "    output_path = drive_path + output_filename\n",
        "    ds_out.to_netcdf(output_path)\n",
        "    print(f\"Saved subset data to {output_path}\\n\")\n",
        "\n",
        "  current_date += timedelta(days=1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "x0OMx5SAPZgx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}