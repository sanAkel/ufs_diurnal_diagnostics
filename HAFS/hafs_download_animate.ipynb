{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMC4sVr6w37LGdH1B7ivTW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanAkel/ufs_diurnal_diagnostics/blob/main/HAFS/hafs_download_animate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PQ1u8xoh4Do"
      },
      "outputs": [],
      "source": [
        "import glob as glob\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_time_coordinates(fName):\n",
        "    ds = xr.open_dataset(fName, decode_times=False)\n",
        "\n",
        "    # Extract initial date string and convert to datetime object\n",
        "    initial_date_str = ds.time.attrs['units'].split('since ')[1]\n",
        "    initial_date = datetime.strptime(initial_date_str, '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Convert time offset values to datetime objects\n",
        "    datetime_values = []\n",
        "    for hour_offset in ds.time.values:\n",
        "        datetime_values.append(initial_date + timedelta(hours=float(hour_offset)))\n",
        "\n",
        "    # Assign the new datetime values to the 'time' coordinate\n",
        "    ds['time'] = datetime_values\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "LQ4w-RhHrGRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs"
      ],
      "metadata": {
        "id": "0V0tuNmjs5mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storm, forecast_start_date, cycle, which_hafs = [\"08l\", \"20250925\", \"00\", \"hfsa\"]\n",
        "\n",
        "vars_to_extract = ['SSH']\n",
        "\n",
        "url_base =\\\n",
        "f'https://noaa-nws-hafs-pds.s3.amazonaws.com/{which_hafs}/{forecast_start_date}/{cycle}/'\n",
        "\n",
        "fName_pref = f'{storm}.{forecast_start_date}{cycle}.{which_hafs}.mom6.f'\n",
        "\n",
        "fName_suff = '.nc'"
      ],
      "metadata": {
        "id": "SvCkoeI7h8Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hrs = np.arange(0,123,3)\n",
        "for hr in hrs:\n",
        "  fName = fName_pref + str(hr).zfill(3) + fName_suff\n",
        "  url = url_base + fName\n",
        "  print(f'Working on\\t{fName}')\n",
        "  !wget -nc -q $url\n",
        "  ds_fix_time = fix_time_coordinates(fName)\n",
        "  ds_cull = ds_fix_time[vars_to_extract]\n",
        "\n",
        "  fName_save = 'subset_' + fName\n",
        "  ds_cull.to_netcdf(fName_save)\n",
        "  print(f'Saved\\n{fName_save}')\n",
        "\n",
        "  ds_fix_time.close()\n",
        "  ds_cull.close()\n",
        "  !rm -f $fName"
      ],
      "metadata": {
        "id": "HWoECqBHiFrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = xr.open_mfdataset(glob.glob('subset_*'), combine='by_coords')"
      ],
      "metadata": {
        "id": "nutUZ2Jeq5zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmocean\n",
        "!pip install cartopy\n",
        "\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "!pip install xmovie"
      ],
      "metadata": {
        "id": "BOpBJ_od3i9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
        "\n",
        "import cmocean as cmo\n",
        "from xmovie import Movie"
      ],
      "metadata": {
        "id": "fI9hE9gO3zhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pltVar(da, fig, tK, *args, **kwargs):\n",
        "  cMin, cMax, cMap = [-0.6, 0.6, 'cmo.balance']\n",
        "\n",
        "  ax1 = fig.add_subplot(111, projection=ccrs.PlateCarree())\n",
        "\n",
        "  # da is a DataArray\n",
        "  im1=da.isel(time=tK).plot(ax=ax1, x='xh', y='yh', transform=ccrs.PlateCarree(), vmin=cMin, vmax=cMax, cmap=cMap, cbar_kwargs={'label': 'SSH [m]', 'pad':0.01, 'shrink':0.9, 'orientation': 'vertical'})\n",
        "\n",
        "  # Get the current time from da_speed for comparison\n",
        "  time_da = da.isel(time=tK).time.values\n",
        "\n",
        "  # tStr should be from the dataarray's time coordinate\n",
        "  tStr = da.isel(time=tK).time.dt.strftime('%Y/%m/%d %H UTC').values\n",
        "  ax1.set_title(f'{tStr}')\n",
        "  ax1.coastlines(resolution='10m', color='k')\n",
        "  ax1.add_feature(cfeature.LAND, facecolor='lightgray')\n",
        "\n",
        "  # Geographical region to plot/compare\n",
        "  roi_lon = [-85, -60]\n",
        "  roi_lat = [15, 30]\n",
        "  ax1.set_extent([roi_lon[0], roi_lon[1], roi_lat[0], roi_lat[1]], crs=ccrs.PlateCarree())\n",
        "\n",
        "  gl = ax1.gridlines(draw_labels=True, dms=True, linewidth=1, ls='--', color='k', alpha=0.5)\n",
        "  gl.top_labels = False\n",
        "  gl.right_labels = False\n",
        "  gl.xformatter = LONGITUDE_FORMATTER\n",
        "  gl.yformatter = LATITUDE_FORMATTER\n",
        "  gl.xlabel_style = {'size': 8}\n",
        "  gl.ylabel_style = {'size': 8}\n",
        "\n",
        "  fig.tight_layout()\n",
        "  #fig.savefig('test.png')"
      ],
      "metadata": {
        "id": "4ldVrpFy2pUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "tK=0\n",
        "pltVar(ds['SSH'], fig, tK)"
      ],
      "metadata": {
        "id": "iDvtdOIl20k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_fName_pref = 'ssh'\n",
        "global_vmin, global_vmax = [-0.6, 0.6]\n",
        "\n",
        "mov = Movie(ds['SSH'], pltVar, pixelwidth=2400, pixelheight=1600, dpi=300, input_check=False)\n",
        "\n",
        "fName_animation = f'{save_fName_pref}_{storm}_{forecast_start_date}{cycle}.{which_hafs}.gif'\n",
        "mov.save(fName_animation, progress=True, overwrite_existing=True, framerate=4, gif_framerate=4, gif_resolution_factor=1)\n",
        "print(f\"Saved animation to {fName_animation}\")"
      ],
      "metadata": {
        "id": "LhXgvbZf4_fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7u1t1qB60Jh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}